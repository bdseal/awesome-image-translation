# Awesome Image-to-image Translation Paper [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A collection of resources on Image Translation. 

This repo is organized chronologically by conferences, another repo which is organized in terms of catrgory is also available. 

## Contributing

If you think I have missed out on something (or) have any suggestions (papers, implementations and other resources), feel free to [pull a request](https://github.com/xiaweihao/awesome-image-translation/pulls)

Feedback and contributions are welcome!


### CVPR 2020

**NICE: Reusing Discriminators for Encoding: Towards Unsupervised Image-to-Image Translation.**<br>
*Runfa Chen, Wenbing Huang, Binghui Huang, Fuchun Sun, Bin Fang.*<br>
CVPR 2020. [[PDF](https://arxiv.org/abs/2003.00273)] [[Github](https://github.com/alpc91/NICE-GAN-pytorch)]

### CVPR 2019 
[[accepted paper list](http://openaccess.thecvf.com/CVPR2019.py)]

**Latent Filter Scaling for Multimodal Unsupervised Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Alharbi_Latent_Filter_Scaling_for_Multimodal_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html)]<br>
*Yazeed Alharbi, Neil Smith, Peter Wonka.*<br>

**Attention-Aware Multi-Stroke Style Transfer.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Attention-Aware_Multi-Stroke_Style_Transfer_CVPR_2019_paper.html)]<br>
*Yuan Yao, Jianqiang Ren, Xuansong Xie, Weidong Liu, Yong-Jin Liu, Jun Wang.*<br>

**Textured Neural Avatars.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Shysheya_Textured_Neural_Avatars_CVPR_2019_paper.html)]<br>
*Aliaksandra Shysheya, Egor Zakharov, Kara-Ali Aliev, Renat Bashirov, Egor Burkov, Karim Iskakov, Aleksei Ivakhnenko, Yury Malkov, Igor Pasechnik, Dmitry Ulyanov, Alexander Vakhitov, Victor Lempitsky.*<br>

**Homomorphic Latent Space Interpolation for Unpaired Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Homomorphic_Latent_Space_Interpolation_for_Unpaired_Image-To-Image_Translation_CVPR_2019_paper.html)] [[Github](https://github.com/yingcong/HomoInterpGAN)]<br>
*[Ying-Cong Chen](https://yingcong.github.io/), Xiaogang Xu, Zhuotao Tian, Jiaya Jia.*<br>

**Multi-Channel Attention Selection GAN With Cascaded Semantic Guidance for Cross-View Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/papers/Tang_Multi-Channel_Attention_Selection_GAN_With_Cascaded_Semantic_Guidance_for_Cross-View_CVPR_2019_paper.pdf)]<br>
*Hao Tang, Dan Xu, Nicu Sebe, Yanzhi Wang, Jason J. Corso, Yan Yan.*<br>

**TraVeLGAN: Image-To-Image Translation by Transformation Vector Learning.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Amodio_TraVeLGAN_Image-To-Image_Translation_by_Transformation_Vector_Learning_CVPR_2019_paper.html)]<br>
*Matthew Amodio, Smita Krishnaswamy.*<br>

**ReversibleGANs for Memory-Efficient ImageTo Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/van_der_Ouderaa_Reversible_GANs_for_Memory-Efficient_Image-To-Image_Translation_CVPR_2019_paper.html)]<br>
*Tycho F.A. van der Ouderaa, Daniel E. Worrall.*<br>

**Image-To-Image Translation via Group-Wise Deep Whitening-And-Coloring Transformation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Cho_Image-To-Image_Translation_via_Group-Wise_Deep_Whitening-And-Coloring_Transformation_CVPR_2019_paper.html)] [[Github](https://github.com/WonwoongCho/GDWCT)]<br>
*Wonwoong Cho, Sungha Choi, David Keetae Park, Inkyu Shin, Jaegul Choo.*<br>

**Towards Visual Feature Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Towards_Visual_Feature_Translation_CVPR_2019_paper.html)]<br>
*Jie Hu, Rongrong Ji, Hong Liu, Shengchuan Zhang, Cheng Deng, Qi Tian.*<br>

**Towards Instance-Level Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Towards_Visual_Feature_Translation_CVPR_2019_paper.html)]<br>
*Zhiqiang Shen, Mingyang Huang, Jianping Shi, Xiangyang Xue, Thomas S. Huang.*<br>

**Art2Real: Unfolding the Reality of_Artworks via Semantically-Aware Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Tomei_Art2Real_Unfolding_the_Reality_of_Artworks_via_Semantically-Aware_Image-To-Image_Translation_CVPR_2019_paper.html)]<br>
*Matteo Tomei, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara.*<br>

**TransGaGa：Geometry-Aware Unsupervised Image To Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_TransGaGa_Geometry-Aware_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1904.09571)] [[project](https://wywu.github.io/projects/TGaGa/TGaGa.html)]<br>
*Wayne Wu, Kaidi Cao, Cheng Li, Chen Qian, Chen Change Loy.*<br>

### ICLR 2019 
[[accepted paper list](https://openreview.net/group?id=ICLR.cc/2019/Conference)]

**InstaGAN: Instance-aware Image-to-Image Translation.** [[PDF](https://openreview.net/forum?id=ryxwJhC9YX)] [[Github](https://github.com/sangwoomo/instagan)]<br>
*Sangwoo Mo, Minsu Cho, Jinwoo Shin.* <br>

**Harmonic Unpaired Image-to-image Translation.** [[PDF](https://openreview.net/forum?id=S1M6Z2Cctm)] <br>
*Rui Zhang, Tomas Pfister, Jia Li.*<br>

**Local Image-to-Image Translation via Pixel-wise Highway Adaptive Instance Normalization.** [[PDF](https://openreview.net/forum?id=HJgTHnActQ)] <br>
*Wonwoong Cho, Seunghwan Choi, Junwoo Park, David Keetae Park, Tao Qin, Jaegul Choo.*

**EG-UNIT: Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency.** [[PDF](https://openreview.net/forum?id=S1lTg3RqYQ)]<br>
*Liqian Ma, Xu Jia, Stamatios Georgoulis, Tinne Tuytelaars, Luc Van Gool.*<br>

**Unsupervised one-to-many image translation.** [[PDF](https://openreview.net/forum?id=B1GIQhCcYm)]<br>
*Samuel Lavoie-Marchildon, Sebastien Lachapelle, Mikołaj Bińkowski, Aaron Courville, Yoshua Bengio, R Devon Hjelm.*<br>

**Unsupervised Image to Sequence Translation with Canvas-Drawer Networks.** [[PDF](https://openreview.net/forum?id=ByeLBj0qFQ)]<br>
*Kevin Frans, Chin-Yi Cheng.*<br>

**Unsupervised Video-to-Video Translation.** [[PDF](https://openreview.net/forum?id=SkgKzh0cY7)]<br>
*Dina Bashkirova, Ben Usman, Kate Saenko.*<br>

### AAAI 2019

**Exploiting Time-Series Image-to-Image Translation to Expand the Range of Wildlife Habitat Analysis.** [[PDF](https://www.aaai.org/ojs/index.php/AAAI/article/view/3862)]<br>
*Ruobing Zheng, Ze Luo, Baoping Yan.*<br>

**Controllable Image-to-Video Translation: A Case Study on Facial Expression Generation.** [[PDF](https://arxiv.org/abs/1808.02992)]<br>
*Lijie Fan, Wenbing Huang, Chuang Gan, Junzhou Huang, Boqing Gong.*<br>

**OT-CycleGAN: Guiding the One-to-one Mapping in CycleGAN via Optimal Transport.** [[PDF](https://arxiv.org/abs/1811.06284)] <br>
*Guansong Lu, Zhiming Zhou, Yuxuan Song, Kan Ren, Yong Yu.*<br> 

### ACM MM 2019

**C2-GAN: Cycle In Cycle Generative Adversarial Networks for Keypoint-Guided Image Generation.**[[PDF](https://arxiv.org/abs/1908.00999)] <br>
*Hao Tang, Dan Xu, Gaowen Liu, Wei Wang, Nicu Sebe, Yan Yan.* <br>

**Towards Automatic Face-to-Face Translation.**[[PDF](https://dl.acm.org/doi/10.1145/3343031.3351066)] [[Github](https://github.com/Rudrabha/LipGAN)] [[Project](http://cvit.iiit.ac.in/research/projects/cvit-projects/facetoface-translation)]<br>
*Prajwal Renukanand, Rudrabha Mukhopadhyay, Jerin Philip, Abhishek Jha, Vinay Namboodiri and C.V. Jawahar.*<br>

**Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation.**[[PDF](https://arxiv.org/abs/1908.07683)]<br>
*Kwanyong Park, Sanghyun Woo, Dahun Kim, Donghyeon Cho, In So Kweon.*<br>
 
**Mocycle-GAN: Unpaired Video-to-Video Translation.**[[PDF](https://arxiv.org/abs/1908.09514)]<br> 
*Yang Chen, Yingwei Pan, Ting Yao, Xinmei Tian, Tao Mei.*<br> 

### Journal 2019

**DRIT++: Diverse Image-to-Image Translation via Disentangled Representations.** <br>
*Hsin-Ying Lee, Hung-Yu Tseng, Qi Mao, Jia-Bin Huang, Yu-Ding Lu, Maneesh Singh, Ming-Hsuan Yang.* <br>
IJCV 2019. [[Project](http://vllab.ucmerced.edu/hylee/DRIT_pp/)] [[Github](https://github.com/HsinYingLee/MDMM)]

**Show, Attend and Translate: Unsupervised Image Translation with Self-Regularization and Attention.** <br>
*Chao Yang, Taehwan Kim, Ruizhe Wang, Hao Peng, C.-C. Jay Kuo.* <br>
TIP 2019. [[PDF](https://arxiv.org/abs/1806.06195)]

**AttGAN: Facial Attribute Editing by Only Changing What You Want.** <br> 
*Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, Xilin Chen.* <br>
TIP 2019. [[PDF](https://arxiv.org/abs/1711.10678)] [[Github](https://github.com/LynnHo/AttGAN-Tensorflow)]

### Others 2019

**RL-GAN: Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation.** <br>
*Shani Gamrian, Yoav Goldberg.* <br>
ICML 2019. [[accepted paper list](http://proceedings.mlr.press/v97/)] [[PDF](https://arxiv.org/abs/1806.07377)] [[Supplementary PDF](http://proceedings.mlr.press/v97/fujimoto19a/fujimoto19a-supp.pdf)] [[Github](https://github.com/ShaniGam/RL-GAN)]

**VR Facial Animation via Multiview Image Translation.** <br>
*Shih-En Wei, Jason Saragih, Tomas Simon, Adam W. Harley, Stephen Lombardi, Michal Perdoch, Alexander Hypes, Dawei Wang, Hernan Badino, Yaser Sheikh.* <br>
SIGGRAPH 2019. [[PDF](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/)]

**Stylizing Video by Example.**<br> 
*Ondřej Jamriška, Šárka Sochorová, Ondřej Texler, Michal Lukáč, Jakub Fišer, Jingwan Lu, Eli Shechtman, Daniel Sýkora.*<br>
SIGGRAPH 2019. [[PDF](https://dcgi.fel.cvut.cz/home/sykorad/Jamriska19-SIG.pdf)]

**VR Facial Animation via Multiview Image Translation.**<br>
*Shih-En Wei, Jason Saragih, Tomas Simon, Adam W. Harley, Stephen Lombardi, Michal Perdoch, Alexander Hypes, Dawei Wang, Hernan Badino, Yaser Sheikh.*<br>
SIGGRAPH 2019. [[PDF](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/)]

**CartoonRenderer: An Instance-based Multi-Style Cartoon Image Translator.** <br>
*Yugang Chen, Muchun Chen, Chaoyue Song, Bingbing Ni.* <br>
International Conference on Multimedia Modeling (MMM2020). [[PDF](https://arxiv.org/abs/1911.06102)] 

**AttentionGAN: Attention-Guided Generative Adversarial Networks for Unsupervised Image-to-Image Translation.**<br>
*Hao Tang, Dan Xu, Nicu Sebe, Yan Yan.* <br>
IJCNN 2019. [[Github](https://github.com/Ha0Tang/AttentionGAN)]

**SMIT: Stochastic Multi-Label Image-to-Image Translation.** <br>
*Andrés Romero, Pablo Arbeláez, Luc Van Gool, Radu Timofte.*<br>
ICCV Workshops 2019. [[PDF](https://arxiv.org/abs/1812.03704)] [[Github](https://github.com/BCV-Uniandes/SMIT)]

**Image-to-Image Translation with Multi-Path Consistency Regularization.** <br>
*Jianxin Lin, Yingce Xia, Yijun Wang, Tao Qin, Zhibo Chen.*<br>
IJCAI 2019. [[PDF](https://arxiv.org/abs/1905.12498)]

**Asymmetric Generative Adversarial Networks for Image-to-Image Translation.** <br>
*Hao Tang, Dan Xu, Hong Liu, Nicu Sebe.*<br>
arxiv, 14 Dec 2019 (ACCV 2018 Extension) [[PDF](https://arxiv.org/abs/1912.06931)] [[GitHub](​​​https://github.com/Ha0Tang/AsymmetricGAN)]

**PPN2V: Fully Unsupervised Probabilistic Noise2Void.** <br>
*Mangal Prakash, Manan Lalit, Pavel Tomancak, Alexander Krull, Florian Jug.*<br>
arxiv, 27 Nov 2019. [[PDF](https://arxiv.org/abs/1911.12291)] [[GitHub](https://github.com/juglab/ppn2v)] [[MPI-CBG: Max-Planck Institute of Molecular Cell Biology and Genetics](https://www.mpi-cbg.de/home/)]

**PN2V:Probabilistic Noise2Void: Unsupervised Content-Aware Denoising.** <br>
*Alexander Krull, Tomas Vicar, Florian Jug.*<br>
arxiv, 3 Jun 2019. [[PDF](https://arxiv.org/abs/1906.00651)] [[Github](https://github.com/juglab/pn2v)]

**Unpaired Image Translation via Adaptive Convolution-based Normalization.** <br>
*Wonwoong Cho, Kangyeol Kim, Eungyeup Kim, Hyunwoo J. Kim, Jaegul Choo.*<br>
arxiv, 29 Nov 2019. [[PDF]( https://arxiv.org/abs/1911.13271)]

**EDIT: Exemplar-Domain Aware Image-to-Image Translation.** <br>
*Yuanbin Fu, Jiayi Ma, Lin Ma, Xiaojie Guo.* <br>
arxiv, 24 Nov 2019. [[PDF](https://arxiv.org/abs/1911.10520)] [[GitHub](http://t.cn/AigvDwW3)]

**Council-GAN: Breaking the cycle - Colleagues are all you need.** <br>
*Ori Nizan, Ayellet Tal.* <br>
arxiv, 24 Nov 2019. [[PDF](https://arxiv.org/abs/1911.10538)]

**injectionGAN: Toward Learning a Unified Many-to-Many Mapping for Diverse Image Translation.**<br>
*Wenju Xu, Shawn Keshmiri, Guanghui Wang.* <br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1905.08766)]

**Cross-Domain Cascaded Deep Feature Translation.** <br>
*Oren Katzir, Dani Lischinski, Daniel Cohen-Or.* <br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1906.01526)]

**AGUIT: Attribute Guided Unpaired Image-to-Image Translation with Semi-supervised Learning.**<br>
*Xinyang Li, Jie Hu, Shengchuan Zhang, Xiaopeng Hong, Qixiang Ye, Chenglin Wu, Rongrong Ji.*<br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1904.12428)] [[Github](https://github.com/imlixinyang/aguit)]

**CrossNet: Latent Cross-Consistency for Unpaired Image Translation.** <br>
*Omry Sendik, Dani Lischinski, Daniel Cohen-Or.*<br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1901.04530)]

### Before 2018
- pix2pix: [[Project](https://phillipi.github.io/pix2pix/)] [[Code](https://github.com/phillipi/pix2pix)] [[Paper](https://arxiv.org/pdf/1611.07004.pdf)]
- BicycleGAN: [[Code](https://github.com/junyanz/BicycleGAN)] [[Tensorflow](https://github.com/gitlimlab/BicycleGAN-Tensorflow)]
- CycleGAN: [[Project](https://junyanz.github.io/CycleGAN/)] [[CycleGAN](https://github.com/junyanz/CycleGAN)] [[pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)] [[Full Paper](https://arxiv.org/pdf/1703.10593.pdf)]
- DualGAN: [[Code](https://github.com/duxingren14/DualGAN)] [[Paper](https://arxiv.org/abs/1704.02510)]
- DiscoGAN: [[Code](https://github.com/carpedm20/DiscoGAN-pytorch)] [[Paper](https://arxiv.org/abs/1703.05192)]
- StarGAN: [[Code](https://github.com/yunjey/StarGAN)] [[Paper](https://arxiv.org/abs/1711.09020)]
- VAE-GAN: [[Code](http://github.com/andersbll/autoencoding_beyond_pixels)] [[Paper](https://arxiv.org/pdf/1611.07004.pdf)]
- UNIT:[[Code](https://github.com/mingyuliutw/UNIT)]
- cVAE-GAN: [[Paper](https://arxiv.org/pdf/1703.10155.pdf)]
- DTN: [[Code](https://github.com/yunjey/domain-transfer-network)] [[Paper](https://arxiv.org/abs/1611.02200)]
- FaderNets: [[Code](https://github.com/facebookresearch/FaderNetworks)] [[Paper](https://arxiv.org/abs/1706.00409)]
- IcGAN: [[Code](https://github.com/Guim3/IcGAN)] [[Paper](https://arxiv.org/abs/1611.06355)]
- GeneGAN: [[Code](https://github.com/Prinsphield/GeneGAN)] [[Paper](https://arxiv.org/abs/1705.04932)]
- Face-Age-cGAN: [[Paper](https://arxiv.org/abs/1702.01983)]
- DAGAN:  Deep Attention GAN


## License

<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
